## 旷视算法实习面经 

**2021/12/6 by kongyan**

**实习岗位**：算法工程师

**总体流程**：自我介绍+项目介绍(重点）+问答（30分钟）+coding(算法题，最终决定)（30分钟）

### 一、数据算法题

> Tips: 由于这块内容相对较少，故放在前面,没有按流程来写

- [x] **求正数平方根**

  考察：二分法

  条件：除0之外任何数的平方根都为[1,本身]之间（循环条件）

  思路：如果mid * mid<=x ：若（mid+1）*（mid+1）> x ,则mid即为平方根，否则说明平方根在[mid+1,x]之间，则left = mid+1

  ​            如果mid*mid > x, 说明平方根在[1,mid-1]之间，则right=mid-1

  [题解](https://leetcode-cn.com/problems/jJ0w9p/)

- [ ] **求正数平方根（精度0.01）**

  **To Do**

- [x] **二分法查找某个数**

  考察：二分法

  思路：每次区间都缩小一半，难点在双指针的临界条件

  **解题模板：**

  ```python 
  def serch(array,target):
      left, right = 0, len(array)-1
      while left <= right:                 # 难点
          mid = left + (right - left) // 2 
          if 条件1：
          	right = mid -1
          elif 条件2：
          	left = mid + 1
          else:
              return mid
  ```

  [leetcode题解](https://leetcode-cn.com/problems/binary-search/submissions/)

- [x] **一个数组里只有一个只出现了一次，其他都只出现了两次，怎么找**

  思路：两个为一组进行比较，总数为奇数

  ```python
  def singleNonduplicate(arr):
      for i in range(0, len(arr)-2, 2):
          if arr[i] != arr[i+1]:
              return arr[i] 
      return arr[-1]
  if __name__ == '__main__':
      arr = [1,1,2,3,3]
      a = singleNonduplicate(arr)
      print(a)
  ```

- [x] **求一个数数列中两个元素最大和，并找到这两个元素（TOP K问题）**

  ```python
  def find_two_num(arr):
      max_sum = 0
      m=0
      n=0
      for i in range(len(arr)-1):
          for j in range(i + 1, len(arr)):
              sum = arr[i] + arr[j]
              if sum > max_sum:
                  max_sum = sum
                  m = i
                  n = j
      print(max_sum)
      print(m,n)
  if __name__ == '__main__':
      arr = [1,3,5,4,2]
      find_two_num(arr)
  ```

- [ ] **求一个数组中只包含0,1使得其中0,1个数相等的子数组**

  **To Do **

- [ ] **两个链表是否相交**

  **To Do **

- [ ] **二叉树后序遍历的非递归实现，及递归实现**

  **To Do **

- [ ] **n个坐标点，固定半径的圆，求圆的坐标使得包括的点最多**

  **To Do **

- [ ] **q754 返回到达终点需要的最小移动次数**

  **To Do **

### 二、DL算法题

1. **IOU 计算**

   ```python
   def IOU(boxA,boxB):
       xA = max(boxA[0], boxB[0])
       yA = max(boxA[1], boxB[1])
   	xB = min(boxA[2], boxB[2])
       yB = min(boxA[3], boxB[3])
       
       inter_area = max(0,(xB - xA) * (yB - yA))
       boxAarea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])
       boxBarea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])
       
       iou = inter_area.flaot() / (boxAarea + boxBarea - inter_area)
       
       return iou
   ```

   

2. **感受野计算**

   [**定义**](https://blog.csdn.net/zyazky/article/details/80967931): 输出feature map某个节点的响应对应的输入图像的区域就是感受野。

   ![image-20211211113216649](https://raw.githubusercontent.com/kongyan66/Img-for-md/master/img/image-20211211113216649.png)

   - **从前到后**  
   $$
     RF_i = RF_{i-1} + (K_{size}-1) * stride_i \\
     K_{size} 和 stride_i 为得到当前特征图所用的卷积核尺寸和步长
   $$
     RF1 = 3
   
     RF2 = 3 + （2-1）x 2 = 5
   
     RF3 = 5 + (3-1) x 1 = 7
   
   ----------
   
   - **从后到前**
     $$
     RF_i = (RF_{i+1} - 1) * stride_i + K_{size}
     $$
     RF3 = 3

     RF2 = (3 - 1) x 2 + 2 = 6

     RF1 = (6-1) x 2 + 3 = 13

4. **BN的实现**

   注意BN的mean和std是在哪个维度求梯度的，mean和std是滑动平均的值。基于Numpy实现

### 三、 基础知识（问答）

**编程相关**

****

+ **python中list, set, dict的区别**

  list和set的数据可变的,tuple和dict的数据是不可变的。list是最自由的,可以使用索引、切片,可以进行计算和修改;tuple是不自由的,数据不能更改,但是和list一样具有序列,可以用索引和切片;dict是半自由的,自由体现在键值对的无序,可以通过key去索引value

+ **multithreading 和 multiprocess的区别，多核是指进程还是线程**

   开一个应用就是一个进程，一个进程可以有多个线程，单CPU中进程只能是并发，多CPU计算机中进程可以并行

+ **32位和64位操作系统的区别在哪，int类型的数据是多少**

  - 64bit CPU拥有更大的寻址能力，最大支持到16GB内存，而32bit只支持4G内存

  - char 1字节  int 4字节  float 4字节

+ **什么是动态联编？**

  指联编在程序运行时动态地进行，根据当时的情况来确定调用哪一个同名函数。实际上是运行时虚函数的实现

**深度学习相关**

****

- **SSD、YOLO、RetinaNet、Faster R-CNN等的原理和优缺点**

  **TO DO**  联系书和网络资源

- **量化原理**

  模型量化即以较低的推理精度损失将连续取值（或者大量可能的离散取值）的浮点型模型权重或流经模型的张量数据定点近似（通常为int8）为有限多个（或较少的）离散值的过程，它是以更少位数的数据类型用于近似表示32位有限范围浮点型数据的过程，而模型的输入输出依然是浮点型，从而达到减少模型尺寸大小、减少模型内存消耗及加快模型推理速度等目标。

- **图像边缘检测有哪些方法**

  Sobel算子、Laplace算子、Canny算子来实现图像的边缘检测

- **为什么要激活函数？**

  特点：1. 非线性  2. 可微性  3. 单调性

  作用：引入非线性因素，、使模型得到强大复杂函数映射能力。

- **为什么要归一化（标准化）？**

  作用：对数据进行归一化和标准化处理，加快网络模型收敛速度，缓解深层网络中梯度弥散的问题。

  联系：两者都能取消由量纲不同引起的误差，都是一种线性变换，都是对向量按比例压缩再进行平移

  区别：归一化将样本特征值转换到同一量纲下，把数据映射到[0,1] 或 [-1,1]区间内，**仅由变量的极值决定**。

  ​            标准化将数据转换为标准正态分布，**每个样本点都能对标准化产生影响**。

- **为什么要正则化**？

  作用：有助于避免过拟合或减少网络误差

  - L1和L2正则化

    就是在原来损失函数基础上加了些正则化项（模型复杂度惩罚函数），L1是加上权重参数的绝对值，L2是加上权重参数的平方和（**结合吴恩达视频看下**）

  - Dropout

    训练阶段丢弃一部分神经元及其连接，过拟合时才用，会导致训练时间变长。

- **梯度消失和梯度爆炸原因及解决办法**

  梯度消失和梯度爆炸的原理差不多，都是因为链式法则的缘故，当后面的网络梯度小于1时，根据链式法则一层层向前传播时会越来越小，最后前面的层的梯度就消失了，梯度爆炸也是一样的道理，后面网络的梯度大于1，前面就爆炸了。

- **过拟合遇到过吗？怎么处理的**

  损失函数加上正则化项；BN；数据增强

- **输出Loss变成Nan了怎么办？**

  估计是超过float32的数据范围了，需要对中间的数据进行归一化，比如BN，sigmoid函数等

- **卷积核的理解，手工怎么设计卷积核,怎么理解权值共享**

  - 也叫滤波器，对输入的某个局部块进行加权求和，实现对应于输入的局部感知（本质是权重参数的矩阵）

  - 卷积核的权值共享只在每个单独通道上有效，对应于输入的一个通道，有一个卷积核的一个通道去对应滑动并且计算过这个通道每一个部分，在这个输入通道的图片或者讲feature map中，我们可以说这个权值是共享的，不同通道间卷积核是独立不共享的。

- **batch normalization训练和测试过程一样吗**

  [CSDN解读](https://blog.csdn.net/weixin_41888257/article/details/107431268)

  不一样，测试时采用整个训练集的均值和方差，不是测试集的（这块具体计算过程不清楚）

- **复现过哪些网络**

  YOLOv1

- **常见主干网络特点，如VGG、GoogLeNet、ResNet(残差连接）、Densenet(密集连接)、Inception**

  **VGG**：1. 整个网络都采用卷积核尺寸3x3和最大池化2x2

  ​            2. 卷积核采用两个3x3代替一个5x5，感受野未变，参数量减少

  **GoogLeNet**:  除了在深度进行延升，采用了最原始的Inception结构增加了网络的**宽度**和**尺度适应性**，缺点是未采用1 * 1卷积，5x5卷积核所需计算量比较大

  ​                       1.采用不同大小的卷积核（不同的感受野)，最后进行不同尺度特征融合（inception）

  ​					   2. 卷积核之所以采用1、3、5，主要是为了方便对齐（W和H一致)

  **Inception**： 卷积块的分解操作，增加了网络的深度和非线性

  **ResNet**: 1. 引入残差连接，使深层网络模型保持原始数据信息且训练过程不宜梯度消失

  ​                 2. 采用瓶颈式网络（bottleneck) ,模仿Inception将3x3卷积拆分为两个1x1和一个3x3卷积组合，有效减少模型参数量

  **DenseNet**：1. 由于密集连接的存在，梯度反向传播非常容易，模型更容易收敛

  ​					  2. 密集连接块中使用增长率k代替较大特征映射维度，可以有效较少模型的参数，提升效率

  ​                      3. 卷积层中采用高维输入低维输出，尽可能排除无用特征

- **阀值是怎么选取,实际意义**

  **To Do **

- **给到一个任务要部署在Android上，你做的逻辑是怎么样**

  **To Do **

- **会去读算法源码**？

  **To Do **

- **直方图均衡化公式推导，作用**

  **To Do **

- **小目标和大目标检测的特征矩阵的深度哪个更深？为什么？**

  **To Do **

- **样本不够多的处理办法**

  **To Do **

- **1 x 1卷积作用**

  1. 实现信息的跨通道交互和整合
  2. 对卷积通道数进行降维和升维，减少参数量
  
- **如何减少卷积层参数量**

  1. 使用堆叠小卷积核代替大卷积核
  2. 使用[深度分离卷积](https://zhuanlan.zhihu.com/p/92134485)操作（KxKxC -> KxKx1 and 1x1xC)
  3. 添加 1x1 卷积操作（降通道数）
  4. 使用池化操作（降低输入维度）

- **什么时候采用3维卷积？**

  只有输入数据是也是三维的，比如视频、医学图像，对于普通RGB图像来说，三个通道没有相关性，本质还是二维的。

- **常用上采样方法，转置卷积原理**

  - 最近邻插值、双线性插值等，以上方法均为人工设计，没有学习参数
  - [转置卷积](https://blog.csdn.net/lanadeus/article/details/82534425)可以通过参数学习最优的上采样方法(具体实现参考卷积通过一次**矩阵乘法**实现方法)



### 四、反问

> 主要问面试官的问题

- **实习的主要工作内容？**
- **自己有什么需要提升的地方？**
- **是否可以推荐到其他岗位？**



​	









