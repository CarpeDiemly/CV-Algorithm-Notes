# 面试

## 自我介绍

面试官，你好！我是沈阳航空天大学信息与通信工程研二学生孔才华， 所在实验室为辽宁省空天信息处理中心重点实验室。研究方向是恶劣气象条件下遥感目标检测。研究生期间，荣获校一等学业奖学金，优秀研究生等荣誉，综合成绩保持专业第一，参加了各类学科竞赛，获得过国家级奖项三项。编程方面，我对python及常用包比较熟悉，对c++有一定了解；深度学习框架，我常用的是Pytorch以及目标检测框架MMDetection。曾有极端项目经历：1.活体计数检测 进行猪场交易、巡查时的清点，目前已交付甲方；2.基于目标检测的货物定位 采用双级定位策略进行目标定位，获得研究生电子设计大赛东北赛区最佳创意奖。 我以第一作者发表SCI(论文)一篇，合作发表CVPR、ECCV各一篇。上半年，我在北京旷视研究院-检测组实习， 主要负责人体姿态算法的研究与落地，参与运动猿BBOX项目，重点参与了仰卧起坐、引体向上、立定跳远动作模型开发、PPL设计、数据回流、持续优化等等工作，目前项目一期工程完成验收。以上是我的简单介绍，谢谢！

## 项目介绍

### 1. 运动猿Box

#### 项目介绍

该项目是面向校园体育教育管理系统，提供素质训练、球类训练、跑步训练等三大类训练项目的人脸检录、成绩判定、违规判定等功能，整合了软件、硬件以及业务逻辑的一套全视觉解决方案。

我主要负责素质训练中立定跳远、硬卧起坐、仰卧起坐的模型、pipeline、数据回流、badcase分析等工作。该项目难点是多模型+多逻辑的零散任务，除了共用的人体检测、骨骼点检测模型外，中间逻辑都需要根据动作类型针对性调整。

![image-20220731153600445](https://raw.githubusercontent.com/kongyan66/Img-for-md/master/img/image-20220731153600445.png)

#### 技术细节

**技术关键词：**数据清洗 skleton检测 PPL设计 可视化 数据回流 仿射变换

PPL  =  人体检测模型 + **骨骼点检测模型** + **计数逻辑** + 违规判别逻辑 + 可视化逻辑 

**数据与模型**：

项目第一步是确定合适的人体估计估计算法，后面逻辑数实现都要依靠它。所以在mentor指导下，我开展了人体估计算法的技术调研，初步选定单帧单人姿态估计的技术方案。它具体又分为了两种路线：

1. Bottom-up  先检测出所有关键点,然后再组装成个体 代表算法有OpenPose、DeeperCut等 
2. Top-Down 先做人体检测, 然后抠出人体区域进行关键点估计 这是比较主流的一种技术方案,代表算法有blazepose、HRNet，  其又可以细分为base_heatmap、直接回归方案。 为了追求稳妥，与mentor商量后，我们选用了单帧 Top-Down & based-heatmap的技术方案，并选定[HRNet](https://github.com/HRNet/HRNet-Human-Pose-Estimation/blob/master/lib/models/pose_hrnet.py)作为baseline,  采用PCKh作为评价指标，使用heapmap作为target, 选用MPII和部分标注的数据15对关键点，进行训练，测试PCKh@0.5指标为0.98，实测分析在在遮挡、模糊等情况出现大量badcase, 考虑关键点天然的位置关系，同时参考[DCLM](https://openaccess.thecvf.com/content_ECCV_2018/papers/Wei_Tang_Deeply_Learned_Compositional_ECCV_2018_paper.pdf)的思想，在原有关键点heatmap基础上，加入了关节连接heatmap, 即多Loss训练， PCKh@0.5提升了5%，改善了hardcase，这对后面计数逻辑十分重要。

**计数策略**

我简单以仰卧起坐的计数策略说明下：

方案一：embedding&[KNN](https://zhuanlan.zhihu.com/p/53084915)

对预测的关键点先进行KNN分类， 优点是比较简单，缺点是训练集需要自己更新，同时分类受关键点质量影响，出现遮挡很容易出现一些误判。

方案二：角度关系

根据测试视频分析，我发在仰卧起坐中遮挡现象出现在在相机视角的对侧，正侧的关键点是相当稳定的，采用角度计数后，技术准确率提升了10%，而且计算量也更小。

**遮挡问题**

这是当前姿态估计最难解决的问题之一，会导致遮挡部分的点跑飞，对后面逻辑产生严重干扰。

首先，我做了一个简单实验，就是把可见点进行人工脑补标注，也当做正样本去学习，但发现提点有限，也就0.2%左右，实际可视化效果还是跑飞。但根据任务特点，我发现我们只需保证重要点正确就好，非重点的点可以不管，后面逻辑也依赖于重要点位，这样就规避了遮挡这个问题，举个例子，仰卧起坐场景，由于人体是侧对着相机的，所以背侧会有遮挡，但两侧是对称的，我们只用正侧的点就能实现计数的逻辑。

**抖动消除**

在实际场景中，我们发现骨骼点会受到遮挡、模糊、掉帧等情况的干扰导致骨骼点不稳定、跑飞现象，这对于后面逻辑实现有重大影响，但这种情况从模型侧改进很难了， 所以我想到用滤波器去除异常点、平滑输出结果。

首先我做了一个简单尝试：增大推理间隔，即间隔三帧一次，这带来了两大好处：1.推理效率提升了3倍 2.减缓了部分抖动情况，实测效果也不错。后来我又进行滤波器的实验，先是采用了传统时序滤波器：如[指数滑动平均滤波](https://zhuanlan.zhihu.com/p/433571477):设置一个滑动窗口，比如将相邻的几帧图片一起送入模型，对结果取平均值; 这些滤波器都需要仔细调校滤波强度，而过强的不可避免地会造成输出结果的滞后，在一些对实时性要求高的场景下不够适用。所以后面我看到一篇[smoother](https://mp.weixin.qq.com/s/qtf7GHxkBTAz50kBkqLuaQ), 相当于基于DL学习一个滤波器，在测试数据上测试误差降低了六个点。

**视频分析**

随着PPL完善，badcase的分析越来越困难，因为是多个模型的集成，如何评判各模型在当前视频表现的质量？所以究竟那一块出现问题人工很难排查出来，所以针对人体检测模型和姿态估计模型输出数据作为参考，去自动分析badcase的情况，分别对检测的置信度和骨骼点的置信度去计算当前值的可信度、抖动程度、可见程度，设定一定的阈值卡视频的表现好坏，最终给出视频质量打分，同时保存badcase的情况作为回流数据进行标注，这里我们同步生成了一个伪标签，减轻再标注的成本。基于这个想法，也诞生出一个应用，用更大的模型去推理伪标签作为预标注，减轻视频标注的成本，这个后来走之前已经交接给另一个同事去做。

##### 其他动作

同时引体向上的计数逻辑类似，对于立定跳远，最重要的是进行垫子标定，即获得刻度线的空间映射。我对原来的人体姿态估计模型进行了简单修改，主要是15对点heatmap改为了30对关键点对应了30条刻度线，之前我也不太确定好使，但通过了过拟合测试就大胆训练了，其他配置基本和骨骼点检测一致，效果也超出了预期。但存在漏点、多点问题，对于漏点，我设计一个补全策略，通过配对关系进行补全。对于多点问题，增大高斯核的kennel来消除。

##### 提升之处

虽然heamap方法准确度高，训练快，但代价是网络要维持较高的分辨率(一般最低是64*64), 这就导致网络参数量大，计算量高，存在量化误差，但对于姿态估计应用主要在移动端上，这是很不友好的，所以更轻量的Regression模型才是未来所需。

目前来说，用fc进行数值回归这个任务的难度，相对来说是比较大的，要让神经网络对应每个位置都预测一个精确的数字，需要很庞大的数据量才能做到比较好的稳定的拟合。

一个降低任务难度的方法是，把一个整体一步到位的回归任务，拆解成一个个局部的拟合，有点分治的思想在里面。用预测heatmap为例，只需要目标位置上那个像素的预测值是最大的就行了，并不要求它跟target的数值一模一样，这本身就降低了任务难度，或者说，就算拟合的精度没有那么高，但只要它是最大的，就能巧妙得到准确的定位了，这本质上有一点用空间换精度的感觉，相当于我们显式地把每个像素给定义出来了，赋予了网络输出空间信息，而不需要网络自己去学习这种空间信息。

最近[Human Pose Regression with Residual Log-likelihood Estimation](https://zhuanlan.zhihu.com/p/395521994) 正式开源，本文走的是用(joint_num*3)维的FC层直接回归出坐标点，



### 2. 智慧活体计数项目 

针对养殖场环境，分别对生猪进行静态计数和动态计数。

#### 技术细节

**技术关键词**：二值化 形态学处理 粒子滤波 Yolov3 Sort DeepSort 数据增强

#### 方案一 传统图像图像处理

**可行条件：**

1. 背景单一，与目标区分度大，有固定光源
2. 流量不是很大 

**实现步骤：**

高斯模糊 -> 中值滤波 -> 转HSV -> 颜色分割 -> 提取轮廓 -> 计数



#### 方案二 深度学习方法

**可行条件：**

1. 提供场景数据采集
2. 场景单一，目标种类有限
3. 现场具备算力支持

**具体步骤：**

1. 数据标注

2. 模型训练

3. 接入sort

4. 计数逻辑

5. 测试

6. 问题调优

   - 高密度，遮挡严重

   - 轨迹不定，存在往返

   - 镜头遮挡

     镜头前设置去除装置

   - 数据分布不均匀

     选取不同时段、不同种类、不同角度、不同场景数据进行扩充，且加入数据增强策略

**升级版本**

针对跟踪失效问题，选用deepsort 算法



### 3. 机器人视觉定位

------

**技术关键词**：移动部署  Fast RCNN  FPN改进  二维码识别 图像校正



### 

## 论文介绍

### 1.无人机多目标检测算法研究

**技术关键词**：有向检测 大尺度

#### Motivation

- **图像级特征错位**：由卷积网络感受野通常轴对称的，对于遥感图像方向任意、尺度多变，主干网络很难提取有效特征。
- **实例级特征错位**：锚框细化阶段，锚框很难表示对于特征所有信息。

对于anchor-based的检测器来说，anchor的设计至关重要，因为他是检测器回归和分类的基准，如果采用滑窗方式生成，anchor中心是均匀分布的，但其形状确实随机的，对于遥感图像，目标方向任意、尺度大，对于人为的设计anchor尺寸要求太高了，因为anchor的回归不会大幅改变anchor 的尺寸，因为尺寸差距过大的话，一开始就因为IoU不满足标注被筛选掉了，参与回归的都是IoU比较大的，所以我们只能设计不同长宽比、不同方向的anchor去更好接近数据集的GT，但这显然增加了计算开销且需要一定的专家经验。

所以有没有一种自动生成anchor的方式呢？或者说只需少量人为设计的anchor呢？首先我们先了解下一个好的anchor有哪些特征：

**从感受野角度**

anchor size设计要兼顾感受野，像ssd中不同大小的feature map要预测不同形状的anchor，感受野小，你给它设计一个很大的anchor，它压根看不到那么大的特征区域，感受野大，你给它设计一个很小的anchor，特征就没那么清晰，比如在一个很大的区域里找一只苍蝇。

**从特征角度**

**alignment**（中心对齐） 和 **consistency**（特征一致）。其中 alignment 是指 anchor 的中心点要和 feature 的位置对齐，consistency 是指 anchor 的特征要和形状匹配。

**alignment**

由于每个 anchor 都是由 feature map 上的一个点表示，那么这个 anchor 最好是以这个点为中心，否则位置偏了的话，这个点的 feature 和这个 anchor 就不是非常好地对应起来，用该 feature 来预测 anchor 的分类和回归会有问题。

**Consistency**

由于每个位置 anchor 形状不同而破坏了特征的一致性，我们需要通过 feature adaption 来进行修正。这条准则本质上是对于如何准确提取 anchor 特征的讨论。对于两阶段检测器的第二阶段，我们可以通过 RoI Pooling 或者 RoI Align 来精确地提取 RoI 的特征。但是对于 RPN 或者单阶段检测器的 anchor 来说，由于数量巨大，我们不可能通过这种 heavy 的方法来实现特征和框的精确 match，还是只能用特征图上一个点，也就是 512x1x1 的向量来表示。那么 Feature Adaption 起到了一个让特征和 anchor 对应更加精确的作用，这种设计在其他地方也有可以借鉴之处。

<img src="https://raw.githubusercontent.com/kongyan66/Img-for-md/master/img/v2-7b716c3c7a9867e7caae7ce87b48ea1b_720w.jpg" alt="img" style="zoom:50%;" />

**所以我们需要让网络自己生成一款感受野合适且特征对齐的一组anchors.**

#### Methods

二阶段检测网络中，ROI operator(例如ROIPooling、RoIAlign、Deformable RoIPolling)采用固定尺寸的特征(近似表示目标位置)，用来目标的分类与定位，但却带来巨大计算花销。[Guided Anchoring](https://zhuanlan.zhihu.com/p/55854246) 通过特征图去预测锚框的中心和形状，大大减少anchor的数量。[AlignDet](https://www.zhihu.com/question/338959309) 通过deformable conv 对齐锚框特征。受次启发，我们提出双阶段特征针对对齐。

第一阶段，选择合适的感受野

为了缓解旋转物体和神经网络感受野之间的错位，我们提出了一个RFS模块，通过使用不同的尺寸的卷积核，并引学习参数角度，通过注意力机制选择最佳的感受野。

第二阶段，对齐旋转锚框的特征

我们设计了由锚优化网络（ARN）和对齐卷积层组成RFA模块，该模块根据锚框的位置大小自适应对齐与目标之间的特征。ARN用于生成高质量的有向锚框，然后由RFA模块进行特征对齐。

#### Problems

考虑速度，设置锚框少，对于重叠物体预测不好

### 2. 去雾与检测领域结合

- 《Unpaired Deep Image Deraining Using Dual Contrastive Learning》CVPR2022
- 《Unpaired Deep Image Dehazing Using Contrastive Disentanglement Learning》 ECCV2022

#### 思考

低级视觉任务仅限于任务本身吗？如何评价低级视觉任务的好坏？是否可由高级视觉任务的去评价低级视觉任务？ 



## 反问

1. 公司主要做那块技术，业务场景有哪些呢，以及是否有一定发展瓶颈？

2. 部门技术氛围怎么样，业务or研究，加班多不多？

   

