# 面试

## 自我介绍

各位面试官，下午好！我叫孔才华，来自沈阳航空航航天大学信息与通信工程专业， 所在实验室为辽宁省空天信息处理与应用中心重点实验室。研究方向多类遥感目标检测。研究生期间，荣获校研究生国家奖学金，优秀研究生，创新创业标兵等荣誉，综合成绩专业第二；参加多项学科竞赛，荣获国家级奖项三项，省级六项。编程方面，我对python及常用包比较熟悉，对c++有一定了解；深度学习框架，我常用的是Pytorch以及目标检测框架MMDetection。曾有过几段项目经历：1.活体计数检测 进行猪场交易、巡查时的数量清点，目前已交付甲方；2.基于目标检测的货物定位 采用双级定位策略进行目标识别与定位，曾获得研究生电子设计大赛东北赛区最佳创意奖。 此外，我以第一作者发表SCI(二区)论文一篇，~~合作发表CVPR、ECCV顶级会议各一篇~~。上半年，我在北京旷视研究院-检测组实习， 主要负责人体姿态算法的研究与落地，参与运动猿BOX项目，重点参与了仰卧起坐、引体向上、立定跳远动作模型开发、PPL设计、数据回流、持续优化等等工作，目前项目已经完成验收。以上是我的简单介绍，谢谢！

**问题**：

1. 贵司主要涉及的技术以及业务场景，对内or对外？
3. 贵司技术技术培养机制，是否有过渡期？
3. 工作中涉及的技术栈，Python or C++ ？
4. 后面还有几轮面试，多久会有反馈？
5. 工作时间，加班的时长。

## 项目介绍

### 1. 运动猿Box

#### 项目介绍

该项目是面向校园体育教育管理系统，提供素质训练、球类训练、跑步训练等三大类训练项目的人脸检录、成绩判定、违规判定等功能，整合了软件、硬件以及业务逻辑的一套全视觉解决方案。

我主要负责素质训练中立定跳远、仰卧起坐、引体向上的模型、pipeline、数据回流、badcase分析等工作。该项目难点是多模型+多逻辑的零散任务，除了共用的人体检测、骨骼点检测模型外，中间逻辑都需要根据动作类型针对性调整。

![image-20220731153600445](https://raw.githubusercontent.com/kongyan66/Img-for-md/master/img/image-20220731153600445.png)

#### 技术细节

**技术关键词：**数据清洗 skleton检测 PPL设计 可视化 数据回流 仿射变换

PPL  =  人体检测模型 + **骨骼点检测模型** + **计数逻辑** + 违规判别逻辑 + 可视化逻辑 

**数据与模型**：

项目第一步是确定合适的人体估计估计算法，后面逻辑数实现都要依靠它。所以在mentor指导下，开展了人体估计算法的技术调研，初步选定单帧单人姿态估计的技术方案。它具体又分为了两种路线：

1. Bottom-up  先检测出所有关键点,然后再组装成个体 代表算法有OpenPose、DeeperCut等 

2. Top-Down 先做人体检测, 然后抠出人体区域进行关键点估计 这是比较主流的一种技术方案,代表算法有blazepose、HRNet，  其又可以细分为heatmap、Regression方案。 为了追求稳妥，与mentor商量后，我们选用了单帧 Top-Down & based-heatmap的技术方案，并选定[HRNet](https://github.com/HRNet/HRNet-Human-Pose-Estimation/blob/master/lib/models/pose_hrnet.py)作为baseline,  采用PCKh作为评价指标，使用heapmap作为target, 选用MPII和部分标注的数据15对关键点，进行训练，测试PCKh@0.5指标为0.92，实测分析在在遮挡、模糊等情况出现大量badcase。

   

3. 考虑关键点固定的位置关系，同时参考DCLM [[论文](https://openaccess.thecvf.com/content_ECCV_2018/papers/Wei_Tang_Deeply_Learned_Compositional_ECCV_2018_paper.pdf) [有代码]()]的思想，在原有关键点heatmap基础上，加入了关节连接heatmap, 即多Loss训练， PCKh@0.5提升了5%，改善了hardcase，这对后面计数逻辑十分重要。

![image-20220823105602339](https://raw.githubusercontent.com/kongyan66/Img-for-md/master/img/image-20220823105602339.png)

DLCM 是一个分层的自下而上和自下而上的组合架构。在自下而上的阶段，首先从图像观察直接回归目标关节的得分图，与现有的基于CNN的HPE方法一样。然后，根据其子级的分数图递归估计更高级别部分的分数图。在自上而下阶段，使用其父母的分数图以及在自下而上阶段估计的他们自己的分数图，递归地细化较低级别部分的分数图。均方误差（MSE）损失用于将预测得分图与地面实况进行比较。通过这种方式，我们可以引导网络学习身体部位之间的组成关系。

**计数策略**

我简单以仰卧起坐的计数策略说明下：

方案一：embedding&[KNN](https://zhuanlan.zhihu.com/p/53084915)

对预测的关键点先进行KNN分类， 优点是比较简单，缺点是训练集需要自己更新，同时分类受关键点质量影响，出现遮挡很容易出现一些误判。

方案二：角度关系

根据测试视频分析，我发在仰卧起坐中遮挡现象出现在在相机视角的对侧，正侧的关键点是相当稳定的，采用角度计数对违规判定简单，计数逻辑也更简单些，准确率提升了10%，而且计算量也更小。

**遮挡问题**

这是当前姿态估计最难解决的问题之一，会导致遮挡部分的点跑飞，对后面逻辑产生严重干扰。

首先，我做了一个简单实验，就是把可见点进行人工脑补标注，也当做正样本去学习，但发现提点有限，也就0.2%左右，实际可视化效果还是跑飞。但根据任务特点，我发现我们只需保证重要点正确就好，非重点的点可以不管，后面逻辑也依赖于重要点位，这样就规避了遮挡这个问题，举个例子，仰卧起坐场景，由于人体是侧对着相机的，所以背侧会有遮挡，但两侧是对称的，我们只用正侧的点就能实现计数的逻辑。

**抖动消除**

在实际场景中，我们发现骨骼点会受到遮挡、模糊、掉帧等情况的干扰导致骨骼点不稳定、跑飞现象，这对于后面逻辑实现有重大影响，但这种情况从模型侧改进很难了， 所以我想到用滤波器去除异常点、平滑输出结果。

首先我做了一个简单尝试：增大推理间隔，即间隔三帧一次，这带来了两大好处：1.推理效率提升了3倍 2.减缓了部分抖动情况，实测效果也不错。后来我又进行滤波器的实验，先是采用了传统时序滤波器：如[指数滑动平均滤波](https://zhuanlan.zhihu.com/p/433571477):设置一个滑动窗口，比如将相邻的几帧图片一起送入模型，对结果取平均值; 这些滤波器都需要仔细调校滤波强度，而过强的不可避免地会造成输出结果的滞后，在一些对实时性要求高的场景下不够适用。所以后面我看到一篇[smoother](https://mp.weixin.qq.com/s/qtf7GHxkBTAz50kBkqLuaQ), 相当于基于DL学习一个滤波器，在测试数据上测试误差降低了六个点。

**视频分析**

随着PPL完善，badcase的分析越来越困难，因为是多个模型的集成，如何评判各模型在当前视频表现的质量？所以究竟那一块出现问题人工很难排查出来，所以针对人体检测模型和姿态估计模型输出数据作为参考，去自动分析badcase的情况，分别对检测的置信度和骨骼点的置信度去计算当前值的可信度、抖动程度、可见程度，设定一定的阈值卡视频的表现好坏，最终给出视频质量打分，同时保存badcase的情况作为回流数据进行标注，这里我们同步生成了一个伪标签，减轻再标注的成本。基于这个想法，也诞生出一个应用，用更大的模型去推理伪标签作为预标注，减轻视频标注的成本，这个后来走之前已经交接给另一个同事去做。

##### 其他动作

同时引体向上的计数逻辑类似，对于立定跳远，最重要的是进行垫子标定，即获得刻度线的空间映射。我对原来的人体姿态估计模型进行了简单修改，主要是15对点heatmap改为了30对关键点对应了30条刻度线，之前我也不太确定好使，但通过了过拟合测试就大胆训练了，其他配置基本和骨骼点检测一致，效果也超出了预期。但存在漏点、多点问题，对于漏点，我设计一个补全策略，通过配对关系进行补全。对于多点问题，增大高斯核的kennel来消除。

##### 提升之处

虽然heamap方法准确度高，训练快，但代价是网络要维持较高的分辨率(一般最低是64*64), 这就导致网络参数量大，计算量高，存在量化误差，但对于姿态估计应用主要在移动端上，这是很不友好的，所以更轻量的Regression模型才是未来所需。

目前来说，用fc进行数值回归这个任务的难度，相对来说是比较大的，要让神经网络对应每个位置都预测一个精确的数字，需要很庞大的数据量才能做到比较好的稳定的拟合。

一个降低任务难度的方法是，把一个整体一步到位的回归任务，拆解成一个个局部的拟合，有点分治的思想在里面。用预测heatmap为例，只需要目标位置上那个像素的预测值是最大的就行了，并不要求它跟target的数值一模一样，这本身就降低了任务难度，或者说，就算拟合的精度没有那么高，但只要它是最大的，就能巧妙得到准确的定位了，这本质上有一点用空间换精度的感觉，相当于我们显式地把每个像素给定义出来了，赋予了网络输出空间信息，而不需要网络自己去学习这种空间信息。

最近[Human Pose Regression with Residual Log-likelihood Estimation](https://zhuanlan.zhihu.com/p/395521994) 正式开源，本文走的是用(joint_num*3)维的FC层直接回归出坐标点，



### 2. 智慧活体计数项目 

针对养殖场环境，分别对生猪进行静态计数和动态计数。

#### 技术细节

**技术关键词**：二值化 形态学处理 粒子滤波 Yolov3 Sort DeepSort 数据增强

#### 方案一 传统图像图像处理

**可行条件：**

1. 背景单一，与目标区分度大，有固定光源
2. 流量不是很大 

**实现步骤：**

高斯模糊 -> 中值滤波 -> 转HSV -> 颜色分割 -> 提取轮廓 -> 计数



#### 方案二 深度学习方法

**可行条件：**

1. 提供场景数据采集
2. 场景单一，目标种类有限
3. 现场具备算力支持

**具体步骤：**

1. 数据标注

2. 模型训练

3. 接入sort

4. 计数逻辑

5. 测试

6. 问题调优

   - 高密度，遮挡严重

   - 轨迹不定，存在往返

   - 镜头遮挡

     镜头前设置去除装置

   - 数据分布不均匀

     选取不同时段、不同种类、不同角度、不同场景数据进行扩充，且加入数据增强策略

**Sort**

Detections 是通过目标检测器得到的目标框， Tracks 是一段轨迹。核心是匹配的过程与卡尔曼滤波的预测和更新过程，简而言之就是维护之前的轨迹，和产生新的轨迹。

流程如下：目标检测器得到目标框 Detections ，同时卡尔曼滤波器预测当前的帧的 Tracks, 然后将Detections 和 Tracks 进行 IOU 匹配，最终得到的结果分为：

-  Unmatched Tracks，这部分被认为是失配， Detection 和 Track 无法匹配, 如果失配持续了$T_{lost}$次，则目标ID将从图片中删除。
-  Unmatched Detections， 这部分说明没有任意一个Track能匹配Detection， 所以要为这个detection分配一个新的Track。
- Matched Track，这部分说明得到了匹配。

<img src="https://raw.githubusercontent.com/kongyan66/Img-for-md/master/img/image-20220822155120578.png" alt="image-20220822155120578" style="zoom:80%;" />

**卡尔曼滤波**

卡尔曼滤波算法分为两个过程，预测和更新。该算法将目标的运动状态定义为 8 个正态分布的向量。

预测：当目标经过移动，通过上一帧的目标框和速度等参数，预测出当前帧的目标框位置和速度等参数。

更新：预测值和观测值，两个正态分布的状态进行线性加权，得到目前系统预测的状态。

**匈牙利算法**

匈牙利算法：解决的是一个分配问题，在 MOT 主要步骤中的计算相似度的，得到了前后两帧的相似度矩阵。匈牙利算法就是通过求解这个相似度矩阵，从而解决前后两帧真正匹配的目标。这部分sklearn 库有对应的函数 linear_assignment 来进行求解。

**Deep sort**

Simple Online and Realtime Tracking(SORT) 是一个非常简单、有效、实用的多目标跟踪算法。在SORT 中，仅仅通过 IOU 来进行匹配虽然速度非常快，但是 ID switch 依然非常大。相比 SORT ，DeepSort 中最大的特点是加入外观信息，借用了 ReID 领域模型来提取特征，减少了 ID switch 的次数。

<img src="https://raw.githubusercontent.com/kongyan66/Img-for-md/master/img/image-20220822153847345.png" alt="image-20220822153847345" style="zoom:80%;" />

可以看出， Deep SORT 算法在 SORT 算法的基础上增加了级联匹配 (Matching Cascade)+ 新轨迹的确认 (confirmed) 。总体流程就是：

- 卡尔曼滤波器预测轨迹 Tracks
- 使用匈牙利算法将预测得到的轨迹 Tracks 和当前帧中的 detections 进行匹配 ( 级联匹配和 IOU匹配 
- 卡尔曼滤波更新。



### 3. 机器人视觉定位

------

**技术关键词**：移动部署  Fast RCNN  FPN改进  二维码识别 图像校正

针对室内场景货物运送难问题，我们团队设计了一款具备货物识别的运送机器人，主要由建图+导航+目标定位三大系统构成，我主要负责目标定位这块，为解决同类目标不同个体的抓取，我们设计了一种由粗到细的双级定目标定位算法，首先通过2D检测器获取货物的粗略位置信息，再通过三维点云匹配，获得货物空间位置信息，同时通过二维码识别，获取货物标签信息，确定目标后，执行抓取操作。

![image-20220822105401494](https://raw.githubusercontent.com/kongyan66/Img-for-md/master/img/image-20220822105401494.png)

#### 问题

**问题一：场景复杂，检测困难**

选用性能更强的二阶段检测网络

**问题二：功能较为复杂，集成困难**

将系统分为三大块完成独立测试后进行联调

**问题三：目标视角多变，二维码识别困难**

通过仿射变换进行校正

#### 2D检测器改进

针对室内货物检测中目标尺寸变化大，目标小，导致检测精度下降的问题，我们以Faster R-CNN为基线，融合改进FPN，采用残差增强模块和空间细化模块，加强特征学习；使用动态卷积池化模块，自适应对齐目标特征。有效缓解了多尺度目标检测易漏检问题，提高小目标检测精度。

![image-20220822111108422](https://raw.githubusercontent.com/kongyan66/Img-for-md/master/img/image-20220822111108422.png)

**多尺度**

输入图片经过ResNet50网络进行特征提取，并利用低层次的SE来建立特征通道之间的关系，我们将空间汇集模块和主干提取的最高级别特征连接在一起，作为自上而下路径模块的输入，并在自上而下的连接中插入三个空间细化块联系上下文信息来学习采样点的位置和内容，将高层特征图上采样后与底层特征图相加，将底层特征图进行下采样后与高层特征图相加的双向融合方式获取最终的特征图，再经过 RPN 网络，生成三种尺度 {256·256 ， 128·128 ， 64·64 } 和三种比例{1:2,1:1,2:1}共 9 种Anchor。之后将其输入到 ROI Pooling 层进行池化操作，最后经过检测器进行输出从而实现目标检测。

**空间细化**

首先，仅基于位置信息对较粗分辨率的特征地图进行上采样是不准确的。第二，不同的采样点包含不同的语义信息，不应具有相同的权重。受可变形转换和空间注意力的启发，我们首先合并相邻层的上下文信息来学习采样点的偏移，然后使用全局信息来细化每个采样点的值。我们的工作和DCN有几个显著的不同。首先，DCN学习每个位置的卷积核的偏移量，而标准参考树学习整个特征映射的每个像素的偏移量。偏移矩阵的参数数量已经减少了很多。其次，SAM结合不同尺度的信息，准确确定采样位置。最后，SAM的重点不仅仅是采样点偏移，而是利用全局信息细化采样权重，使得采样结果更加准确。

<img src="https://raw.githubusercontent.com/kongyan66/Img-for-md/master/img/image-20220822111831939.png" alt="image-20220822111831939" style="zoom:150%;" />

#### 点云匹配

![image-20220822111334133](https://raw.githubusercontent.com/kongyan66/Img-for-md/master/img/image-20220822111334133.png)

#### 二维码识别

首先截取检测目标有效区域，经过灰度处理、图像平滑及二值化等预处理，同时为适应实际场景视角多变问题，采用基于Canny和Hough变换的二维码旋转进行校正。

## 论文介绍

### 1.无人机多目标检测算法研究

**技术关键词**：有向检测 大尺度

#### Motivation

- **图像级特征错位**：由卷积网络感受野通常轴对称的，对于遥感图像方向任意、尺度多变，主干网络很难提取有效特征。
- **实例级特征错位**：锚框细化阶段，锚框很难表示对于特征所有信息。

对于anchor-based的检测器来说，anchor的设计至关重要，因为他是检测器回归和分类的基准，如果采用滑窗方式生成，anchor中心是均匀分布的，但其形状确实随机的，对于遥感图像，目标方向任意、尺度大，对于人为的设计anchor尺寸要求太高了，因为anchor的回归不会大幅改变anchor 的尺寸，因为尺寸差距过大的话，一开始就因为IoU不满足标注被筛选掉了，参与回归的都是IoU比较大的，所以我们只能设计不同长宽比、不同方向的anchor去更好接近数据集的GT，但这显然增加了计算开销且需要一定的专家经验。

所以有没有一种自动生成anchor的方式呢？或者说只需少量人为设计的anchor呢？首先我们先了解下一个好的anchor有哪些特征：

**从感受野角度**

anchor size设计要兼顾感受野，像ssd中不同大小的feature map要预测不同形状的anchor，感受野小，你给它设计一个很大的anchor，它压根看不到那么大的特征区域，感受野大，你给它设计一个很小的anchor，特征就没那么清晰，比如在一个很大的区域里找一只苍蝇。

**从特征角度**

**alignment**（中心对齐） 和 **consistency**（特征一致）。其中 alignment 是指 anchor 的中心点要和 feature 的位置对齐，consistency 是指 anchor 的特征要和形状匹配。

**alignment**

由于每个 anchor 都是由 feature map 上的一个点表示，那么这个 anchor 最好是以这个点为中心，否则位置偏了的话，这个点的 feature 和这个 anchor 就不是非常好地对应起来，用该 feature 来预测 anchor 的分类和回归会有问题。

**Consistency**

由于每个位置 anchor 形状不同而破坏了特征的一致性，我们需要通过 feature adaption 来进行修正。这条准则本质上是对于如何准确提取 anchor 特征的讨论。对于两阶段检测器的第二阶段，我们可以通过 RoI Pooling 或者 RoI Align 来精确地提取 RoI 的特征。但是对于 RPN 或者单阶段检测器的 anchor 来说，由于数量巨大，我们不可能通过这种 heavy 的方法来实现特征和框的精确 match，还是只能用特征图上一个点，也就是 512x1x1 的向量来表示。那么 Feature Adaption 起到了一个让特征和 anchor 对应更加精确的作用，这种设计在其他地方也有可以借鉴之处。

<img src="https://raw.githubusercontent.com/kongyan66/Img-for-md/master/img/v2-7b716c3c7a9867e7caae7ce87b48ea1b_720w.jpg" alt="img" style="zoom:50%;" />

**所以我们需要让网络自己生成一款感受野合适且特征对齐的一组anchors.**

#### Methods

二阶段检测网络中，ROI operator(例如ROIPooling、RoIAlign、Deformable RoIPolling)采用固定尺寸的特征(近似表示目标位置)，用来目标的分类与定位，但却带来巨大计算花销。[Guided Anchoring](https://zhuanlan.zhihu.com/p/55854246) 通过特征图去预测锚框的中心和形状，大大减少anchor的数量。[AlignDet](https://www.zhihu.com/question/338959309) 通过deformable conv 对齐锚框特征。受次启发，我们提出双阶段特征针对对齐。

第一阶段，选择合适的感受野

为了缓解旋转物体和神经网络感受野之间的错位，我们提出了一个RFS模块，通过使用不同的尺寸的卷积核，并引学习参数角度，通过注意力机制选择最佳的感受野。

第二阶段，对齐旋转锚框的特征

我们设计了由锚优化网络（ARN）和对齐卷积层组成RFA模块，该模块根据锚框的位置大小自适应对齐与目标之间的特征。ARN用于生成高质量的有向锚框，然后由RFA模块进行特征对齐。

#### Problems

考虑速度，设置锚框少，对于重叠物体预测不好

### 2. 去雾与检测领域结合

- 《Unpaired Deep Image Deraining Using Dual Contrastive Learning》CVPR2022
- 《Unpaired Deep Image Dehazing Using Contrastive Disentanglement Learning》 ECCV2022

#### 思考

低级视觉任务仅限于任务本身吗？如何评价低级视觉任务的好坏？是否可由高级视觉任务的去评价低级视觉任务？ 



## 反问

1. 公司主要做那块技术，业务场景有哪些呢，以及是否有一定发展瓶颈？

2. 部门技术氛围怎么样，业务or研究，加班多不多？

   

