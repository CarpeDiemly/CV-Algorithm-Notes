

# 算法笔记

## Motivation

此帖子用来记录 CV基础知识，对知识点的自我理解，采用问答形式去掌握核心

**备忘录**

- [高阶卷积——卷积神经网络总结](https://icode.best/i/76636746663252)

- 



## DL基础

### 1. 前向传播与反向传播计算

https://www.jianshu.com/p/964345dddb70

### 2.梯度爆炸和梯度消失

https://blog.51cto.com/u_15274944/2924098

### 3.如何计算卷积参数量和计算量

https://www.jianshu.com/p/c2a0ba5bb3d1

https://zhuanlan.zhihu.com/p/395354063

https://blog.csdn.net/Brikie/article/details/112646865  归纳了计算通式，比较简洁

https://zhuanlan.zhihu.com/p/92134485 图解正常卷积和分离卷积，非常直观

#### 正常卷积

**计算参数量**

**参数量**：从卷积核数量角度去想，就是卷积核pixel的总数

**通式**: 参数量 = 每个卷积核的参数 x 核的数量(输出通道数) + 偏置(输出通道数）

用于衡量模型大小
$$
params = (k_{w}*k_{h}*C_{in} + 1(bias))*C_{out}
$$
**计算计算量**

**计算量(FlOPs**)：注意s小写  从输出特征的pixel计算量角度去想, 要区别与FLOPS。

**通式：**Flops =  计算每个输出特征值的 乘法次数 + 加法次数 + 通道合并次数(忽略) + 偏置(输出通道数)

可以用来衡量算法/模型的复杂度

对于一个输出为WxHxC的Featture map，我们可以先计算得到一个通道上一个点(pixel)所用的计算量,再计算特征图所有点的
$$
乘法运算数M=k_{w}*k_h*C_{in} \\
加法运算数A=（k_{w}*k_h-1）*C_{in} \\
通道运算数C=C_{in} - 1 \\  
则 Flops= (M+A+C+1(bisa))*W_{out}*H_{out}*C_{out}\\
化简得到：Flops = (2*k_w*k_h*C_{in})*W_{out}*H_{out}*C_{out}
$$

#### 可分离卷积

可分离的卷积具体操作是先对输入map每单个channel进行卷积的操作(分组卷积)，然后再进行1x1卷积实现输出通道的改变(1*1全卷积)。

![微信截图_20220707161709](https://raw.githubusercontent.com/kongyan66/Img-for-md/master/img/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20220707161709.png)

**参数量：**

分两部分计算，每层单独卷积和1维卷积
$$
params = k_w*k_h*C_{in} + (1*1*C_{in}+1(bias))*C_{out}
$$
**计算量**

同上也分两部分，计算量计算遵循正常卷积计算公式来


$$
FLOPs = (2*k_w*k_h*1) * W_{out}*H_{out}*C_{in} + (2*1*1*C_{in})*W_{out}*H_{out}*C_{out}\\
化简的：FLOPs = 2*(K_w*K_h + C_{out})*W_{out}*H_{out}*C_{in}
$$
**结论**：对比发现，采用分离卷积，得到同样的Featture map, 参数量和计算量都大大减小了，这样可以设计出更深的网络。



### 4.计算感受野

#### Receptive filed(RF)概念

卷积神经网络每一层输出特征图的中每一个像素映射到原始输入图像区域的大小

#### 卷积输入与输出关系

根据感受野的概念，大家可以体会到感受野的计算应该与卷积的计算是相反的过程，所以先回顾下卷积输入输出的大小关系公式：（以高度为例）
$$
Height_{out} = (Height_{in} - F+2*P)/S + 1
$$
其中`F`为滤波器的边长，`P`为padding的大小，`S`为步长。

#### 感受野计算

计算感受野和计算卷积计算是一个相反的过程，采用`Top—Down`方式，具题步骤为：

1. 设要计算感受野的这层为N层
2. 第N层到第N-1层的感受野就是对第N-1层进行卷积时使用滤波器的大小，这里我们设置为$RF_{N-1}$。
3. 接着计算第`N`层到第`N-2`层的感受野大小，公式是：
   $$RF_{N-2} = (RF_{N-1} -1)*stride + kernel\_size$$ **（需要注意的是这里的`stride`和`kernel_size`是第`N-2`层的）**
 4. 一直迭代第３步直至输入层，即可算出第N层的感受野

这里大家注意下第３步中的公式，体会下是不是刚好与上面卷积输入输出的关系刚好反过来，$RF_{N-2}$对应$Height_{in}$，$RF_{N-1}$对应$Height_{out}$。唯一的区别是不需要管padding，这也说明了感受野其实是包括padding在内的，所以你会发现算出来的感受野大小可能会比原始图像的大小还要大。

如上一段所说，**其实这样的计算方法是有一点问题的，没有考虑padding和pooling部分，要做修改。但这种方法还是可以应对面试时候的感受野计算问题的**，若是研究过程中要计算非常准确的感受野大小的话，还是得再深入研究下，大家可以看看下面的两个参考资料。

#### 参考资料

[如何计算感受野(Receptive Field)——原理](https://zhuanlan.zhihu.com/p/31004121)
[Calculate Receptive Field for VGG16](http://zike.io/posts/calculate-receptive-field-for-vgg-16/)













## 检测基础

### 1. 如何计算mAP?

<u>原理：掌握   代码：了解伪代码</u>

> **问题：**
>
> 1)   AP及mAP 计算过程？
>
> 2）PR曲线如何绘制的，怎么反应模型性能好坏的，怎么找到二者的平衡？
>
> 3)  为何PR曲线中precision 与recall成负相关？

#### **基础概念**

**TP**：正确的检测的数量：正确分类且为正样本/前景（IOU >= threshold)

**FP**：错误的检测的数量：IOU <= threshold

**FN**: 漏检的数量

**TN**: 没有意义。因为我们只关注前景，不会去检测背景的框，没事找事啊

**Precision**: 反应模型找到正确检测框的能力
$$
precision = TP/(TP + FP) = TP/all-detections
$$
**Recall**:反应模型找到所有真实框的能力
$$
Recall = TP/(TP+FN) = TP/all-ground-truths
$$
**AP**: 平均精度，在不同recall下的最高precision的均值(一般会对各类别分别计算各自的AP)。

**mAP**:  平均精度的均值，各类别的AP的均值。

#### AP及mAP计算过程

ap是针对于一个类别，所以以下举其中一类的例子

**第一步：排序**

我们通过inference获得一批检测框(coordinate, score), 数量记作，然后按照类别划分，我们拿出其中一类的检测框，数量记作**n_dets**, 然后根据每个框的socre得分，降序排列，这样就得到一个序列（n_dets, score)。

**第二步：由IOU求TP、FP**

将每个检测框与GT做IOU计算，大于阈值即为TP，小于则为FP，此时已经可以计算出一组precision和recall

**第三步：动态计算precision&recall**

为啥说动态，因为我们调整score的阈值，从小到大依次累加，会影响检测框的总数，所以会得到不同组的precision和recall

这也是我们画PR曲线的基础

第四步：计算AP

voc07:如果按照[VOC07](https://arleyzhang.github.io/articles/1dc20586/)的AP计算标准

，对于0.0-1.0的11个Recall阈值(间隔0.1），分别取每个阈值之上的最大Precision进行计算平均值(**11-point interpolation**)

![img](https://camo.githubusercontent.com/dfe080e1379c29387ed57b9ac23e72001a94f0e5b8eb02c69f1d6d3b2161e663/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f2535437465787425374241502537442533442535436672616325374231253744253742313125374425323025354373756d5f25374272253543696e2532302535436c65667425323025354325374225323030253243253230302e312532432532302e2e2e25324331253230253543726967687425323025354325374425374425354372686f5f25374225354374657874253742696e746572702537442535436c656674253230253238253230722532302535437269676874253230253239253744)

voc12: AP等于PR曲线的面积（ **interpolating all points**）

#### PR曲线绘制

由上面动态计算得到的Recall & Precision, 我们对应到（x,y)即可绘制出PR曲线。

**PR曲线特点**：

- recall 越小， precision反而越大，二者负相关

  因为如果把score阈值值很高，检测框数量就少(大量漏检），即算precison的分母很小，同时导致TP变小，自然结果值就大。但recall分母是GT的数量，这个是不变的，只有分子(TP)数量提高才能变大。

- 一般来说，我们希望上述两个指标都是越高越好。比较不同检测器效果，一般通过其面积来看，直观点就是如果一个学习器的P-R被另一个学习器的该曲线包围，则可以断言后面的要好些，如果有交叉点，我们就可以通过平衡点(准确率=召回率)，此图说明性能A>B>c

  <img src="https://raw.githubusercontent.com/kongyan66/Img-for-md/master/img/20170826114737648.png" alt="img" style="zoom:67%;" />

### 2. anchor-free 与anchor-based区别

基于anchor-based方法：本质是对是先验框(anchor)的分类与回归。

基于anchor-free方法: 用锚点去分类和回归detect-box



### 3.ROIPooling、RoIAlign、Deformable RoIPolling区别

`RoIPooling`将RoI的浮点数边界量化为整数，这会导致RoI和特征之间的错位。

`RoIAlign`采用bilinear interpolation算子区域中每个采样位置的提取值，从而避免了量化误差

`Deformable RoIPolling`为RoI的每个子区域添加偏移，从而实现自适应特征选择。

### 4.one-stage 和two-stage区别

通常是人为设计的一组框，作为分类（classification）和框回归（bounding box regression）的基准框。无论是单阶段（single-stage）检测器还是两阶段（two-stage）检测器，都广泛地使用了 anchor。

**two-stage**: anchor -> proposal -> detection bbox

**one-stage**: anchor -> detection bbox



### 5.anchor如何生成的

常见的生成 anchor 的方式是滑窗（sliding window），也就是首先定义 k 个特定尺度（scale）和长宽比（aspect ratio）的 anchor，然后在全图上以一定的步长滑动。这种方式在 Faster R-CNN，SSD，RetinaNet 等经典检测方法中被广泛使用。