## 前言

map是**Mean Average Precision**的缩写，翻译过来是平均精度的平均。有点绕啊，在理解map之前，先问个为什么要引入map，在分类任务中，常使用精确率和召回率作为评价指标，也称查准率和查全率，这是一个简单直接的统计量。目标检测任务稍有不同的是，即使目标检测器检测到猫和狗，没有定位，这也是没有用的。所以我们评价这个目标检测器的性能，**不仅要评价它检测的对不对，还要评价它定位的准确性，这里就引入了map这个指标。**

## AP的计算

经过一系列的训练过后，怎么才能判断我们目标检测训练模型的效果呢，首先我们要有**包含标签的验证集**，没有标签就没办法评价；其次知道目标检测任务是用来干嘛的，我们以一个实例举例，如在植物大战僵尸中，坚果+地雷是绝佳配合。

![img](https://img-blog.csdnimg.cn/ac0100880c4f462c865a7c0837d9edcb.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5omA5ZCR5oqr6Z2h55qE5byg5aSn5YiA,size_12,color_FFFFFF,t_70,g_se,x_16)

但是坚果要放在地雷前面才有效果，我们需要检测地雷和坚果以及两者的位置。如下图。

![img](https://raw.githubusercontent.com/kongyan66/Img-for-md/master/img/0f48b3b5704949e7bf17ffe2f92d74dd.png)

> 评价目标模型的效果，是要评价出检测的准确性。预测框有三个信息：**位置、类别、对应类别的置信度**，首先AP计算是分类别计算的，先抽出某一类别的预测框和GT框，分两步：第一步**预测框与GT框的匹配**，第二步进行**相关precision 、recall以及AP的计算**。

### 1.预测框与GT框的匹配

假如我们先计算坚果的AP，首先就是找出所有预测类为坚果的预测框，如下图红色的框。先做**单一类别的AP计算**，抽出坚果的预测框（红色1，2，3，4， 5，6，7）和坚果的真实框。

![img](https://raw.githubusercontent.com/kongyan66/Img-for-md/master/img/548e005ff77f462bbc4f68ef6d2af779.png)

**我们通过`IOU` 来评判定位的准确性。**先计算各预测框与GT框的IOU值，设IOU阈值为0.5，则过滤掉`1、2、4、7`框（1，2，7框因为IOU小于阈值，4框虽然和地刺的GT框重合，但是他检测的类别是坚果的，也是不行的），`3，5、6`均满足IOU值**，但5、6匹配到了同一个GT框上了，而一个GT只能匹配到一个GT框(主要用于后面计算recall)，在一般的目标检测过程中，会先通过`NMS`将预测框过滤掉后再计算mAP, 这里假设没有过滤完全，取score高的作为匹配框。则`3、6`框为匹配到的预测框。匹配完坚果，以同样的方式匹配到地刺。

### 2.指标计算

这里先了解下混淆矩阵,这块有点绕，对目标检测来说：

![img](https://raw.githubusercontent.com/kongyan66/Img-for-md/master/img/2b55a21709d541439b2c4667cb1750b1.png)

**P和N是对应预测框被预测成正样本还是负样本，T和F是预测框预测的对不对，是否被正确的分类。**

目标检测中，训练时通过人为定义正负样本，去让模型学习哪些是目标，哪些是背景，如与GT的IOU值高于阈值的图像区域为正样本，小于阈值的图像区域为负样本。所有大于置信度阈值的框均为预测**正样本（P）**,**与GT的IOU高于IOU阈值的为TP，反之为FP**。没有预测出来的框都是N，目标检测一般不区分TN和FN。因为目标检测预测对应的框为背景是正确的似乎也没多大意义。因此，目标检测中，一般不考虑TN。

> 对于坚果类别(置信度阈值为0.2， IOU阈值为0.5）：
> True Positive (TP): 真的正样本，实际为正样本，检测为正样本，目标检测上是IOU>=阈值的检测框，这里的3和6框
> False Positive (FP): 假的正样本，实际为负样本，检测为正样本，目标检测上：IOU<阈值的检测框，或者是检测到同一个GT的多余检测框的数量，这里的1、2、4、5和7框
> True Negative (TN): 真的负样本，实际为负样本，检测为负样本，忽略。
> False Negative (FN): 假的负样本，实际为正样本，检测为负样本，最下面**漏检**的那个坚果。

**准确率计算公式：**

所有预测框中预测正确的比率。

![img](https://raw.githubusercontent.com/kongyan66/Img-for-md/master/img/720761105d35488d9dc08cdadd70ed9a.png)

**召回率计算：**

所有GT框中预测正确的比率。

![img](https://raw.githubusercontent.com/kongyan66/Img-for-md/master/img/1d95060150a54b038bb45f2d983bf94b.png)

### 3. AP计算

如何计算每个类别的AP呢，首先AP的定义是PR曲线围成的面积，所以我们需要先求PR曲线，对于PR曲线的采样点，voc10前后有两种不同的方式，voc08只选取Recall >= 0, 0.1, 0.2, …, 1共11个点时的Precision最大值，然后AP就是这11个Precision的平均值，称为Interplolated AP。如我们上面预测的坚果：



## mAP 计算

一般来说，在计算完**每个类别的ap**后，对于整个数据集的**map**，采用对各类别ap的平均值>

对于COCO 评价方式稍有不同，如下图：

<img src="https://raw.githubusercontent.com/kongyan66/Img-for-md/master/img/4553944720814358b5c4593977f5d6a7.png" alt="img" style="zoom:50%;" />

第一个mAP为IOU的阈值从固定的0.5调整为在 0.5 - 0.95 的区间上每隔0.5计算一次AP的值，取所有结果的平均值作为最终的结果。

第二个map为不同尺寸的物体的mAP。包括小物体、中等物体、大物体，后面描述了物体对应的像素值的大小。

第三、第四为平均召回率，和AP相似，但这个不太常用。



## mAP的实现



## 结语

根据 mAP 的高低，我们只能较为概括地知道网络整体性能的好坏，但比较难分析问题具体在哪。举个例子：如果网络输出的框很贴合，选择合适的 Confidence 阈值时，检出和召回也较均衡，但是目标的类别判断错误较多。由于首先根据类别结果分类处理，只要类别错了，定位、检出和召回都很好，mAP 指标也不会高。**但从结果观察，并不能很明确知道，问题出在类别判断上还是定位不准确上面。**

mAP 指标关注的点，与实际应用时关注的点，并不完全吻合，mAP 会统计所有 Confidence 值下的 PR值，而实际使用时，会设定一个 Confidence 阈值，低于该阈值的目标会被丢弃，这部分目标在统计 mAP 时也会有一定的贡献。部分针对比赛刷榜的涨点技巧，会关注这部分检测结果对 mAP 的影响。

所以针对具体的目标检测项目需求，map仅仅只能大概的评估模型性能，还需要其他的评价指标。

## 参考

[CSDN_从零讲解目标检测的评价指标map及实现](https://blog.csdn.net/zqwwwm/article/details/124408093)